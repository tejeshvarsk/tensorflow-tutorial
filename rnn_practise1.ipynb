{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2345046-5b71-43e7-8d91-c6f28dddd2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6aa95723-dc4b-4d6d-af2a-66a138e864c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(file_path, 'rb').read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "837e610d-76e7-4fb3-b727-412be330547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=tf.strings.unicode_split(text, input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0bc28e1-ce8f-4288-a2f6-ed295c30f83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5298d569-d4dd-4613-afb4-bf63eafb1a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[[40, 41, 42]],\n",
       " [[63, 64]]]>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input=tf.strings.unicode_split([['abc'],['xy']],input_encoding='UTF-8')\n",
    "ids_from_chars=tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None)\n",
    "ids=ids_from_chars(example_input)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bff54c88-172d-4315-82e4-ae485a60bab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[[b'a', b'b', b'c']],\n",
       " [[b'x', b'y']]]>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None, invert=True)\n",
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e018a768-c5a1-4146-8cad-ea2c8da1b3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allids = ids_from_chars(tf.strings.unicode_split(text,input_encoding='UTF-8'))\n",
    "allids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "94804b75-1c15-423e-835c-1df89f8f5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(allids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e1dd9d7-d693-437d-a113-9ffe46d4b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length=100\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61987a49-60ea-43d5-8599-a524def49790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text= sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6df7d67e-9336-4c4b-90e5-30ba79926242",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0588963b-529c-4f31-ad37-9f22e1582bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE=10000\n",
    "BATCH_SIZE=64\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8774b8bd-ebb1-42db-a4e3-8aafdbeb0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=256\n",
    "rnn_units=1024\n",
    "vocab_size=len(ids_from_chars.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d055154b-023d-48a6-bd94-c3fbeac4e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, rnn_units, embedding_dim, vocab_size):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "    def call(self, input, states=None, return_state=False, training=False):\n",
    "        x= input\n",
    "        x= self.embedding(x,training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x,states = self.gru(x, initial_state=states)\n",
    "        x = self.dense(x)\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3ea5a558-0c05-4fe6-84ac-1879ecdf3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(rnn_units, embedding_dim, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24ddb946-f273-4f79-a71e-1d4998f5245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dae02-37a1-46f1-ae66-9157c99bad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "141/172 [=======================>......] - ETA: 24s - loss: 1.6536"
     ]
    }
   ],
   "source": [
    "EPOCHS=30\n",
    "history=model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "054fc715-3680-4380-91eb-d0cd36d0a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4772c8c4-f310-4d28-95cd-2392a4a412d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example prediction shape : (64, 100, 66)\n"
     ]
    }
   ],
   "source": [
    "for example_input_batch, example_target_batch in dataset.take(1):\n",
    "    example_predictions = model(example_input_batch)\n",
    "    print(f'Example prediction shape : {example_predictions.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9d8b1ae5-23af-4b8e-aed8-9a1e5b7e5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, ids_from_chars, chars_from_ids, temperature=1):\n",
    "        super().__init__(self)\n",
    "        self.model = model\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.temperature = temperature\n",
    "        skip_ids = ids_from_chars(['[UNK]'])[:,None]\n",
    "        sparse_mask = tf.SparseTensor(indices=skip_ids, \n",
    "                                      values=[-float('inf')]*len(skip_ids), \n",
    "                                      dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        x = tf.strings.unicode_split(inputs, input_encoding='UTF-8')\n",
    "        x = self.ids_from_chars(x).to_tensor()\n",
    "        predicted_logits, states = self.model(x, states, return_state=True)\n",
    "        predicted_logits = predicted_logits[:,-1,:]\n",
    "        \n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "        return predicted_chars, states\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "08b5830a-7e5e-4b12-b972-ccb9a02d06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "onestep_model = OneStep(model, ids_from_chars, chars_from_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2bae9907-7855-477b-a9da-646b8d98c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_char=tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for i in range(1000):\n",
    "    next_char, states = onestep_model.generate_one_step(next_char, states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c0b85725-bbbb-4c93-81f6-4629138fbc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"ROMEO:\\nWhou fear mut is a campol' frey Wimour so fealatly.\\n\\nPirst:\\nAs he't moned with Plivized\\nOt, the charty and my contentings, go'tlys that\\nTho caul on the dight wer receit.\\n\\nTRING LEDWARD II VI:\\nWhat, his redour eyeps a fail\\nTreakes pord to die duedion mant.\\n\\nCAMINCEL:\\nVo thy feelly twance, thoued re put inseambed my tach\\nHot eorp. usen:\\nI say, out egamenspeds?\\nWhere thou ore gone; lets what, incliar in mo\\nnos their them woble I marding mour\\nThew's nebsey, and outher alf than gave upon the merney?\\nSopelvey in th sheefs reasen's it oners and all priad you,\\nMary strept she dour frawer stire baghtle\\nWhe came and betten have sons; it at whint\\nWhich sut ut bood that it youre pase: and thee agon the mort.\\n\\nCLIOND:\\nThe fats, duth doobs of consperily and evernds this?\\n\\npordoRY:\\nA prismio, that are it you a te:\\nYour love, sidst shrugh\\nWhich havo mad menm'd he dsand arate break down\\nHore.\\nTo som.\\n\\nRICHARD:\\nSiren my foll3 AVles conwilats,--\\n\\nFhold Provercain:\\nMay no slat, good my forreay, fearher.\\n\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4545c8c-2ade-4c15-a359-96eef0b2dd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
