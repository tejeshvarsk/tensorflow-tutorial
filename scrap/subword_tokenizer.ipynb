{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b83795b-926e-4ef7-9371-7df4cecb01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8050cff-4366-4009-81fc-799335ed4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "train_ex = examples['train']\n",
    "val_ex = examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4de9bcf-4265-499d-8132-65df1465c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 09:02:00.559576: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for pt,en in train_ex.take(1):\n",
    "    print(pt.numpy().decode('utf-8'))\n",
    "    print(en.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cedb0009-35ad-4de3-bd44-ac1f823e7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = train_ex.map(lambda pt,en : en)\n",
    "train_pt = train_ex.map(lambda pt,en : pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c42dc3-30f8-415a-bb90-a48595e2342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e47b50c-b468-4abd-8414-a8b2cd43c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer_params = dict(lower_case=True)\n",
    "reserved_tokens=['[UNK]','[PAD]','[START]','[END]']\n",
    "vocab_args= dict(vocab_size=8000,\n",
    "    reserved_tokens=reserved_tokens,\n",
    "    bert_tokenizer_params=bert_tokenizer_params,\n",
    "    learn_params={})\n",
    "vocab_en = bert_vocab.bert_vocab_from_dataset(train_en.batch(1000).prefetch(2), **vocab_args)\n",
    "vocab_pt = bert_vocab.bert_vocab_from_dataset(train_pt.batch(1000).prefetch(2), **vocab_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f6c9d2-ce68-4d33-9e5c-91c7f6269ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vocab_to_file(vocab, file_path):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for tokens in vocab:\n",
    "            print(tokens, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13300166-0d13-40ba-aa39-0531b1c07b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vocab_to_file(vocab_en, \"vocab_en.txt\")\n",
    "write_vocab_to_file(vocab_pt, \"vocab_pt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed606fa6-cfb2-4fda-ab8f-ab4da5aa2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = text.BertTokenizer(\"vocab_en.txt\", **bert_tokenizer_params)\n",
    "tokenizer_pt = text.BertTokenizer(\"vocab_pt.txt\", **bert_tokenizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c73a3be3-eba5-4f7c-a172-7c2ca3f972ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72], [117], [79], [1259], [1491, 2362], [13], [79], [150], [184], [311],\n",
      "  [71], [103], [2308], [74], [2679], [13], [148], [80],\n",
      "  [55, 4840, 1434, 2423, 540], [15]]                                       ,\n",
      " [[87], [90], [107], [76], [129], [1852], [30]],\n",
      " [[87], [83], [149], [50], [9], [56], [664], [85], [2512], [15]]]>\n"
     ]
    }
   ],
   "source": [
    "for ex in train_en.batch(3).take(1):\n",
    "    print(tokenizer_en.tokenize(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f19f4bc3-d9c7-426f-a985-156b21a56ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
       "array([b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .',\n",
       "       b'but what if it were active ?',\n",
       "       b\"but they did n't test for curiosity .\"], dtype=object)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9c3aec1-2037-48c4-b6d4-7d80e5cc74c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74,\n",
       "  2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15]                       ,\n",
       " [87, 90, 107, 76, 129, 1852, 30],\n",
       " [87, 83, 149, 50, 9, 56, 664, 85, 2512, 15]]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_batch = tokenizer_en.tokenize(ex).merge_dims(-2,-1)\n",
    "token_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5812aaa-0c9f-4353-8af9-32cf662900ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'and', b'when', b'you', b'improve', b'search', b'##ability', b',',\n",
       "  b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n",
       "  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n",
       "  b'##ity', b'.']                                                          ,\n",
       " [b'but', b'what', b'if', b'it', b'were', b'active', b'?'],\n",
       " [b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for', b'curiosity',\n",
       "  b'.']                                                                    ]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tf.gather(vocab_en, token_batch)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39efdd0d-f37c-47ee-9bfb-16513bd45540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_end(ragged):\n",
    "    size = ragged.bounding_shape()[0]\n",
    "    start = tf.argmax(tf.constant(reserved_tokens)=='[START]')\n",
    "    end = tf.argmax(tf.constant(reserved_tokens)=='[END]')\n",
    "    start = tf.fill((size,1), start)\n",
    "    end = tf.fill((size,1), end)\n",
    "    return tf.concat([start, ragged, end], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1086fbbd-7a85-4bf8-9919-ec836e993e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308,\n",
       "  74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]               ,\n",
       " [2, 87, 90, 107, 76, 129, 1852, 30, 3],\n",
       " [2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_start_end(token_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "818dd802-f592-4ab6-881a-832489e48f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability',\n",
       "  b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n",
       "  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n",
       "  b'##ity', b'.', b'[END]']                                                 ,\n",
       " [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n",
       "  b'[END]']                                                           ,\n",
       " [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n",
       "  b'curiosity', b'.', b'[END]']                                          ]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tf.gather(vocab_en, add_start_end(token_batch))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15f9f17f-32c3-41c9-b8fd-e0c682f4ca58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'searchability', b',',\n",
       "  b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n",
       "  b'of', b'print', b',', b'which', b'is', b'serendipity', b'.', b'[END]'] ,\n",
       " [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n",
       "  b'[END]']                                                           ,\n",
       " [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n",
       "  b'curiosity', b'.', b'[END]']                                          ]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.detokenize(add_start_end(token_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a1b7690-eb4c-47a2-b710-5401e90e53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(token_text):\n",
    "    bad_tokens = [re.escape(token) for token in reserved_tokens if token != '[UNK]']\n",
    "    bad_tokens_re = '|'.join(bad_tokens)\n",
    "    bad_locs = tf.strings.regex_full_match(token_text, bad_tokens_re)\n",
    "    cleaned_tokens = tf.ragged.boolean_mask(token_text, ~bad_locs)\n",
    "    return tf.strings.reduce_join(cleaned_tokens, separator=' ', axis=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c8ca6d7-64a3-4445-b33b-e0e5732777a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
       "array([b'and when you improve search ##ability , you actually take away the one advantage of print , which is s ##ere ##nd ##ip ##ity .',\n",
       "       b'but what if it were active ?',\n",
       "       b\"but they did n ' t test for curiosity .\"], dtype=object)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_text(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c22a8a05-82a0-4fb6-9687-2e4970e89180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
       "array([b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .',\n",
       "       b'but what if it were active ?',\n",
       "       b\"but they did n ' t test for curiosity .\"], dtype=object)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_text(tokenizer_en.detokenize(add_start_end(token_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f843d9a5-ca00-4316-bb69-758bdbd7f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer(tf.Module):\n",
    "    def __init__(self, reserved_tokens, vocab_path):\n",
    "        self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True)\n",
    "        self._reserved_tokens=reserved_tokens\n",
    "        self._vocab_path = tf.saved_model.Asset(vocab_path)\n",
    "        vocab = pathlib.Path(vocab_path).read_text().splitlines()\n",
    "        self.vocab=tf.Variable(vocab)\n",
    "        self.tokenize.get_concrete_function(tf.TensorSpec(shape=[None], dtype=tf.string))\n",
    "        self.detokenize.get_concrete_function(tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n",
    "        self.detokenize.get_concrete_function(tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n",
    "        self.lookup.get_concrete_function(tf.TensorSpec(shape=[None,None], dtype=tf.int64))\n",
    "        self.lookup.get_concrete_function(tf.RaggedTensorSpec(shape=[None,None], dtype=tf.int64))\n",
    "        self.get_reserved_tokens.get_concrete_function()\n",
    "        self.get_vocab_path.get_concrete_function()\n",
    "        self.get_vocab_size.get_concrete_function()\n",
    "    @tf.function\n",
    "    def tokenize(self, txt):\n",
    "        tokens = self.tokenizer.tokenize(txt).merge_dims(-2,-1)\n",
    "        return add_start_end(tokens)\n",
    "    @tf.function\n",
    "    def detokenize(self, tokens):\n",
    "        words = self.tokenizer.detokenize(tokens)\n",
    "        return cleanup_text(words)\n",
    "    @tf.function\n",
    "    def lookup(self, tokens):\n",
    "        words = tf.gather(self.vocab, tokens)\n",
    "        return words\n",
    "    @tf.function\n",
    "    def get_reserved_tokens(self):\n",
    "        return self._reserved_tokens\n",
    "    @tf.function\n",
    "    def get_vocab_path(self):\n",
    "        return self._vocab_path\n",
    "    @tf.function\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2abe3d74-10f1-4505-bedd-ea5fc1badda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers=tf.Module()\n",
    "tokenizers.pt = CustomTokenizer(reserved_tokens, 'vocab_pt.txt')\n",
    "tokenizers.en = CustomTokenizer(reserved_tokens, 'vocab_en.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3814c309-c1ed-4673-9515-263848e50881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: krishna_tokenizer/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: krishna_tokenizer/assets\n"
     ]
    }
   ],
   "source": [
    "model_name='krishna_tokenizer'\n",
    "tf.saved_model.save(tokenizers, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "990603ed-90eb-4f79-a7c3-6ff17d0cfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_tokenizer = tf.saved_model.load(model_name)\n",
    "reconstructed_en = reconstructed_tokenizer.en\n",
    "reconstructed_pt = reconstructed_tokenizer.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5459aab1-8c0e-47c5-b02d-f3857a90197f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7010>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_en.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86707702-cf89-4f45-bd2d-e34294db2b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[2, 4006, 2358, 687, 1192, 2365, 4, 3]]>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = reconstructed_en.tokenize(['Hello Tensorflow!'])\n",
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66dff5e6-ace3-47f8-87bd-2260894c8e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'[START]', b'hello', b'tens', b'##or', b'##f', b'##low', b'!',\n",
       "  b'[END]']]>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_en.lookup(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8545bf08-c3a1-4d1b-b250-2e8470bafea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'hello tensorflow !'], dtype=object)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_en.detokenize(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bdb83-4078-4a0f-9fe0-8efcba32b9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
